# CAD Evaluation

*As part of MEng project "Mitigating Hallucinations in LLMs", supervised by Dr Marcus Tomalin*

**Main repository:** https://github.com/stephen1cowley/additive-cad

This repository contains the main evaluation code used in evaluating CAD and Additive CAD in the project.

The code of interest used to evaluate on MemoTrap is `long_test.py`. The code of interest used to evaluate on the Natural Questions dataset is `long_test_nq.py`. Additional scripts for extracting probability distributions on questions of interest can be found in `additional_scripts/`.

The variant of the Natural Questions dataset used (too large to contain in this repo) can be found here: https://github.com/stephen1cowley/additive-cad/tree/main/nq/orig_dev_filtered.json.
